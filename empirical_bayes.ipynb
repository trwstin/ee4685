{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirical Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from scipy.stats import norm, boxcox\n",
    "from scipy import stats\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = 'red'\n",
    "data_set = 'white'\n",
    "df = pd.read_csv(\"winequality-\"+data_set+\".csv\", sep=\";\")\n",
    "#df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['fixed acidity', 'volatile acidity', 'citric acid',\n",
    "       'residual sugar', 'chlorides', 'free sulfur dioxide',\n",
    "       'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n",
    "\n",
    "Q1 = df[cols].quantile(0.25)\n",
    "Q3 = df[cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "df = df[~((df[cols] < (Q1 - 1.5 * IQR)) |(df[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"fixed acidity\"], _ = boxcox(df[\"fixed acidity\"])\n",
    "df[\"residual sugar\"], _ = boxcox(df[\"residual sugar\"])\n",
    "df[\"free sulfur dioxide\"], _ = boxcox(df[\"free sulfur dioxide\"])    \n",
    "df[\"total sulfur dioxide\"], _ = boxcox(df[\"total sulfur dioxide\"])\n",
    "df[\"alcohol\"], _ = boxcox(df[\"alcohol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Redefining classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the target variable (quality) into 3 classes.\n",
    "- Class 0 : Bad (quality <= 4)\n",
    "- Class 1 : Average (5 <= quality <= 7)\n",
    "- Class 2 : Good (8 <= quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 3769, 3: 149, 1: 97})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(\"quality\", axis=1)\n",
    "\n",
    "classes = []\n",
    "for i in df['quality']:\n",
    "    if i<=4:\n",
    "        classes.append(1)\n",
    "    elif i >= 5 and i <= 7:\n",
    "        classes.append(2)\n",
    "    elif i >= 8:\n",
    "        classes.append(3)\n",
    "df['classes'] = classes\n",
    "\n",
    "Counter(df['classes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardisation\n",
    "The features are not directly comparable as they represent different physical quantities, we need to standardise them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal Components Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=8)\n",
    "X = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the data in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size = 0.25, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=random_seed)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 2827, 3: 2827, 1: 2827})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimal Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "class BayesOptimalClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_priors = {}\n",
    "        self.class_conditional_dists = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the classifier by computing priors and likelihoods\"\"\"\n",
    "        n_samples, _ = X.shape\n",
    "        classes = np.unique(y)\n",
    "\n",
    "        # Compute class priors P(C_k)\n",
    "        class_counts = Counter(y)\n",
    "        self.class_priors = {c: class_counts[c] / n_samples for c in classes}\n",
    "\n",
    "        # Compute P(X | C_k) assuming Gaussian distributions for each feature\n",
    "        self.class_conditional_dists = {}\n",
    "        for c in classes:\n",
    "            X_c = X[y == c]\n",
    "            self.class_conditional_dists[c] = {\n",
    "                \"mean\": X_c.mean(axis=0),\n",
    "                \"std\": X_c.std(axis=0, ddof=1) + 1e-9  # Avoid division by zero\n",
    "            }\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Compute posterior probabilities for each class\"\"\"\n",
    "        posteriors = []\n",
    "        for x in X:\n",
    "            class_probs = {}\n",
    "            for c in self.class_priors:\n",
    "                prior = self.class_priors[c]\n",
    "                likelihood = np.prod(norm.pdf(x, self.class_conditional_dists[c][\"mean\"], \n",
    "                                              self.class_conditional_dists[c][\"std\"]))\n",
    "                class_probs[c] = prior * likelihood\n",
    "            # Normalize probabilities\n",
    "            total = sum(class_probs.values())\n",
    "            posteriors.append({c: class_probs[c] / total for c in class_probs})\n",
    "        return posteriors\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the most probable class for each instance\"\"\"\n",
    "        posteriors = self.predict_proba(X)\n",
    "        return np.array([max(p, key=p.get) for p in posteriors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesOptimalClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.08      0.65      0.14        26\n",
      "           2       0.97      0.50      0.66       942\n",
      "           3       0.07      0.61      0.13        36\n",
      "\n",
      "    accuracy                           0.50      1004\n",
      "   macro avg       0.37      0.59      0.31      1004\n",
      "weighted avg       0.91      0.50      0.62      1004\n",
      "\n",
      "Accuracy:  0.5049800796812749\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print('\\n',classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
