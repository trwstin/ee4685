{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_white = pd.read_csv('winequality-white.csv', delimiter=';')\n",
    "df_red = pd.read_csv('winequality-red.csv')\n",
    "\n",
    "df = pd.concat([df_white, df_red])\n",
    "\n",
    "# Create a quality label (low, medium, high) based on quality score\n",
    "df['quality_label'] = df['quality'].apply(lambda x: 'Poor' if x < 5 else 'Average' if x <= 7 else 'High')\n",
    "\n",
    "# Encode 'quality_label' to numerical values\n",
    "label_enc = LabelEncoder()\n",
    "df['quality_label'] = label_enc.fit_transform(df['quality_label'])\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Separate the data into features and target\n",
    "X = df.drop(['quality', 'quality_label'], axis=1).to_numpy()\n",
    "y = df['quality_label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "model = RandomForestClassifier(min_samples_split=2, max_depth=20, n_estimators=100, random_state=42)\n",
    "std_scaler = StandardScaler()\n",
    "rb_scaler = RobustScaler() # robust works slightly better\n",
    "sampler = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE\n",
    "X_samp, y_samp = sampler.fit_resample(X, y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_samp, y_samp, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data after split to prevent information leak\n",
    "X_train = rb_scaler.fit_transform(X_train)\n",
    "X_test = rb_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n",
      "Best Parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# GridSearchCV for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Quality Labels:\n",
      " {'Average': 0, 'High': 1, 'Poor': 2}\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      1501\n",
      "           1       0.93      0.99      0.96      1491\n",
      "           2       0.95      0.98      0.97      1445\n",
      "\n",
      "    accuracy                           0.95      4437\n",
      "   macro avg       0.95      0.95      0.95      4437\n",
      "weighted avg       0.95      0.95      0.95      4437\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Encoded Quality Labels:\\n', dict(zip(label_enc.classes_, label_enc.transform(label_enc.classes_))))\n",
    "print('\\n', classification_report(y_test, best_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.94421907 0.93914807 0.91274941 0.93473115 0.84173148]\n",
      "Mean cross-validation score: 0.9145158358376759\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(best_model, X_samp, y_samp, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean cross-validation score: {cv_scores.mean()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
